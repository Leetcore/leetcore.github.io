<!DOCTYPE html>
<html lang="de">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <title>Recon Deutschland</title>
</head>

<body>
    <div id="main">
        <h3><a href="/blog">1337core Blog</a></h3>
        <h1>Recon Deutschland</h1>
        <span id="date">15.08.2022</span>
        <article>
            <p>
                Mal eben alle Webseiten der öffentlichen Verwaltung in ganz 
                Deutschland abchecken? Geht! Automatisierung macht halt auch 
                Laune. Zuerst hab ich mir die Daten von Wikipedia runter 
                gezogen wie so ein Amateur. Richtig gute Leute finden Wikidata.
            </p>
            <p>
                Der Query Builder, um dort Daten zu finden, ist zwar ziemlich 
                komplex, aber mit Hilfe konnte ich ihn benutzen. Meine 
                Community rockt mal wieder. <b>!love</b>
            </p>
            <h2>Vorgehen</h2>
            <p>
                Wenn man die URLs von Wikidata hat, nimmt man nur die Domain 
                und checkt dann erstmal die Subdomains und Hosts. Danach mit 
                irgendeinem Script die typischen Webseitenports anfragen. Davon 
                die Banner ziehen mit Server-Version und Titel. Das ergibt eine 
                schöne Liste, die mit <i>grep</i> auch schnell durchsucht ist.
            </p>
            <p>
                Eine aktuelle Liste davon ist hier: 
                <a href="https://github.com/Leetcore/recon-deutschland">Recon Deutschland</a>.
            </p>
        </article>
    </div>
</body>

</html>